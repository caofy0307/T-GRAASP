{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/shareN/data8/SwapTmp/fy/Spatial/ARGA-ARVGA/\")\n",
    "\n",
    "from math import e\n",
    "from re import L\n",
    "import numpy\n",
    "import torch\n",
    "import os.path as osp\n",
    "from typing import List, Optional\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_value_\n",
    "import pandas\n",
    "from torch.nn import MSELoss, CrossEntropyLoss\n",
    "from torch.nn import Module, ModuleList, Sequential, Linear, ReLU, SELU\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn.inits import reset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import knn_graph, ChebConv, GINConv, GraphNorm, GAE, VGAE\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from scripts.CustomFunc import onehot_to_label, sqrtm\n",
    "from torch_geometric.utils import to_dense_batch, to_dense_adj, dense_to_sparse, negative_sampling\n",
    "from torch_geometric.nn.dense.mincut_pool import _rank3_trace\n",
    "from scripts.SGEDataset import SGEDataset\n",
    "from scripts.SGWTConv import SGWTConv\n",
    "from scripts.SGEModel import ResNet, PPIEdgeConv, DynamicEdgeConv\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import os\n",
    "\n",
    "EPS = 1e-15\n",
    "MAX_LOGSTD = 10\n",
    "MAX = 10.\n",
    "MIN = -10.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import torch\n",
    "import os.path as osp\n",
    "from typing import List\n",
    "from torch_geometric.data import InMemoryDataset, download_url, Data\n",
    "from torch_geometric.utils import dense_to_sparse, remove_self_loops, to_undirected\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "#generate dataset from whole-genome HiC data\n",
    "#SGE2 = SGEDataset(root='/public/home/qiyuan/Projects/Spatial/', name='SGE2', id=sample_id)\n",
    "class SGEDataset1(InMemoryDataset):\n",
    "    url = ''\n",
    "    def __init__(self, root: str, name: str, id: List[str], transform=None, pre_transform=None):\n",
    "        self.name = name\n",
    "        self.id = id\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "    @property\n",
    "    def raw_dir(self) -> str:\n",
    "        return osp.join(self.root, self.name, 'raw')    \n",
    "    @property\n",
    "    def processed_dir(self) -> str:\n",
    "        return osp.join(self.root, self.name, 'processed1')\n",
    "    @property\n",
    "    def raw_file_names(self) -> List[str]:         \n",
    "        files = ['hvg_counts.txt', 'truth.txt']    \n",
    "        return [f'{i}_{f}' for i in self.id for f in files]  \n",
    "    @property\n",
    "    def processed_file_names(self) -> str:\n",
    "        return 'data.pt'\n",
    "    def process(self):\n",
    "        data_list = []\n",
    "        for i in self.id:\n",
    "            print(f'sample ID: {i}')\n",
    "            nodes = pandas.read_csv(f'{self.raw_dir}/{i}_hvg_counts.txt', sep=' ', header=0,index_col=0)\n",
    "            x = torch.tensor(nodes.values, dtype=torch.float).transpose(0, 1)\n",
    "            node_id = nodes.columns.values\n",
    "            node_label = pandas.read_csv(f'{self.raw_dir}/{i}_truth.txt', sep=' ', header=0,index_col=0) \n",
    "            print(node_label) \n",
    "            node_barcode = node_label['barcode'].values\n",
    "            print(node_barcode)\n",
    "            if not all(node_id == node_barcode):\n",
    "                try:\n",
    "                    raise Exception('Node IDs do not match!')\n",
    "                except Exception as error:\n",
    "                    print(error) \n",
    "            node_celltype = node_label['layer'].values.tolist()\n",
    "            print(node_celltype)\n",
    "            y = torch.tensor(node_celltype, dtype=torch.float32)\n",
    "            j = torch.where(~torch.isnan(y))    \n",
    "            edge_index = torch.Tensor(2, 0) #empty edges    \n",
    "            pos = pandas.read_csv(f'{self.raw_dir}/{i}_position.txt', sep=' ', header=0,index_col=0) \n",
    "            print(pos)\n",
    "            # coord = torch.tensor(pos.iloc[:,-2:].values, dtype=torch.float32) \n",
    "            coord = torch.tensor(pos.iloc[:,[4, 5]].values, dtype=torch.float32)   \n",
    "            dst = torch.tensor(pairwise_distances(coord[j], metric='euclidean'))\n",
    "            # print(dst)\n",
    "            cut = torch.sort(dst[:,100])[0][6]+5\n",
    "            adj = (dst < cut).int()\n",
    "            edge_index, _ = dense_to_sparse(adj)\n",
    "            edge_index, _ = remove_self_loops(edge_index)\n",
    "            edge_index = to_undirected(edge_index)\n",
    "            edge_weight = torch.ones_like(edge_index[0])\n",
    "            batch = torch.zeros(x.size(0))\n",
    "            g = Data(x=x[j], y=y[j].long(), edge_index=edge_index, edge_weight=edge_weight,batch = batch)\n",
    "            data_list = data_list + [g]\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(num_nodes, train_ratio=0.5):\n",
    "    mask = torch.rand(num_nodes) < train_ratio\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import torch\n",
    "import os.path as osp\n",
    "from typing import List\n",
    "from torch_geometric.data import InMemoryDataset, download_url, Data\n",
    "from torch_geometric.utils import dense_to_sparse, remove_self_loops, to_undirected\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "#generate dataset from whole-genome HiC data\n",
    "#SGE2 = SGEDataset(root='/public/home/qiyuan/Projects/Spatial/', name='SGE2', id=sample_id)\n",
    "def SGEDataset(id: str, raw_dir: str):\n",
    "    data_list = []\n",
    "    for i in id:\n",
    "        print(f'sample ID: {i}')\n",
    "        nodes = pandas.read_csv(f'{raw_dir}/{i}_hvg_counts.txt', sep=' ', header=0,index_col=0)\n",
    "        x = torch.tensor(nodes.values, dtype=torch.float).transpose(0, 1)\n",
    "        node_id = nodes.columns.values\n",
    "        node_label = pandas.read_csv(f'{raw_dir}/{i}_truth.txt', sep=' ', header=0,index_col=0) \n",
    "        # print(node_label) \n",
    "        node_barcode = node_label['barcode'].values\n",
    "        # print(node_barcode)\n",
    "        if not all(node_id == node_barcode):\n",
    "            try:\n",
    "                raise Exception('Node IDs do not match!')\n",
    "            except Exception as error:\n",
    "                print(error) \n",
    "        node_celltype = node_label['layer'].values.tolist()\n",
    "        # print(node_celltype)\n",
    "        y = torch.tensor(node_celltype, dtype=torch.float32)\n",
    "        j = torch.where(~torch.isnan(y))    \n",
    "        num_nodes = len(y[j])\n",
    "        train_mask = create_mask(num_nodes)\n",
    "        test_mask = ~train_mask\n",
    "        edge_index = torch.Tensor(2, 0) #empty edges    \n",
    "        pos = pandas.read_csv(f'{raw_dir}/{i}_position.txt', sep=' ', header=0,index_col=0) \n",
    "        # print(pos)\n",
    "        # coord = torch.tensor(pos.iloc[:,-2:].values, dtype=torch.float32) \n",
    "        coord = torch.tensor(pos.iloc[:,[4, 5]].values, dtype=torch.float32)   \n",
    "        dst = torch.tensor(pairwise_distances(coord[j], metric='euclidean'))\n",
    "        # print(dst)\n",
    "        cut = torch.sort(dst[:,100])[0][6]+5\n",
    "        adj = (dst < cut).int()\n",
    "        adj1 = adj[train_mask]\n",
    "        adj1 = adj1[:,train_mask]\n",
    "        adj2 = adj[test_mask]\n",
    "        adj2 = adj2[:,test_mask]\n",
    "        edge_index1, _ = dense_to_sparse(adj1)\n",
    "        edge_index1, _ = remove_self_loops(edge_index1)\n",
    "        edge_index1 = to_undirected(edge_index1)\n",
    "        edge_index2, _ = dense_to_sparse(adj2)\n",
    "        edge_index2, _ = remove_self_loops(edge_index2)\n",
    "        edge_index2 = to_undirected(edge_index2)\n",
    "        edge_weight1 = torch.ones_like(edge_index1[0])\n",
    "        edge_weight2 = torch.ones_like(edge_index2[0])\n",
    "        batch1 = torch.zeros(adj1.size(0)).to(device)\n",
    "        batch2 = torch.zeros(adj2.size(0)).to(device)\n",
    "        g = Data(x=x[j][train_mask], y=y[j][train_mask].long(), edge_index=edge_index1, edge_weight=edge_weight1,batch = batch1)\n",
    "        g1 = Data(x=x[j][test_mask], y=y[j][test_mask].long(), edge_index=edge_index2, edge_weight=edge_weight2,batch = batch2)\n",
    "        data_list = [g,g1]\n",
    "        return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 1, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 1, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "raw_dir='/shareN/data8/SwapTmp/fy/Spatial/ARGA-ARVGA/SGE2/raw'\n",
    "id=\"151676\"\n",
    "\n",
    "nodes = pandas.read_csv(f'{raw_dir}/{id}_hvg_counts.txt', sep=' ', header=0,index_col=0)\n",
    "x = torch.tensor(nodes.values, dtype=torch.float).transpose(0, 1)\n",
    "node_id = nodes.columns.values\n",
    "node_label = pandas.read_csv(f'{raw_dir}/{id}_truth.txt', sep=' ', header=0,index_col=0) \n",
    "# print(node_label) \n",
    "node_barcode = node_label['barcode'].values\n",
    "# print(node_barcode)\n",
    "if not all(node_id == node_barcode):\n",
    "    try:\n",
    "        raise Exception('Node IDs do not match!')\n",
    "    except Exception as error:\n",
    "        print(error) \n",
    "node_celltype = node_label['layer'].values.tolist()\n",
    "# print(node_celltype)\n",
    "y = torch.tensor(node_celltype, dtype=torch.float32)\n",
    "j = torch.where(~torch.isnan(y)) \n",
    "num_nodes = len(y[j])\n",
    "train_mask = create_mask(num_nodes)\n",
    "test_mask = ~train_mask\n",
    "edge_index = torch.Tensor(2, 0) #empty edges    \n",
    "pos = pandas.read_csv(f'{raw_dir}/{id}_position.txt', sep=' ', header=0,index_col=0) \n",
    "# print(pos)\n",
    "# coord = torch.tensor(pos.iloc[:,-2:].values, dtype=torch.float32) \n",
    "coord = torch.tensor(pos.iloc[:,[4, 5]].values, dtype=torch.float32)   \n",
    "dst = torch.tensor(pairwise_distances(coord[j], metric='euclidean'))\n",
    "# print(dst)\n",
    "cut = torch.sort(dst[:,100])[0][6]+5\n",
    "adj = (dst < cut).int()\n",
    "adj1 = adj[train_mask]\n",
    "adj1 = adj1[:,train_mask]\n",
    "adj2 = adj[test_mask]\n",
    "adj2 = adj2[:,test_mask]\n",
    "print(adj1)\n",
    "edge_index1, _ = dense_to_sparse(adj1)\n",
    "edge_index1, _ = remove_self_loops(edge_index1)\n",
    "edge_index1 = to_undirected(edge_index1)\n",
    "edge_index2, _ = dense_to_sparse(adj2)\n",
    "edge_index2, _ = remove_self_loops(edge_index2)\n",
    "edge_index2 = to_undirected(edge_index2)\n",
    "edge_weight1 = torch.ones_like(edge_index1[0])\n",
    "edge_weight2 = torch.ones_like(edge_index2[0])\n",
    "batch = torch.zeros(x.size(0))\n",
    "g = Data(x=x[j][train_mask], y=y[j][train_mask].long(), edge_index=edge_index1, edge_weight=edge_weight1,batch = batch)\n",
    "g1 = Data(x=x[j][test_mask], y=y[j][test_mask].long(), edge_index=edge_index2, edge_weight=edge_weight2,batch = batch)\n",
    "data_list = [g,g1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample ID: 151507\n"
     ]
    }
   ],
   "source": [
    "sample_id = [\"151507\"]\n",
    "d = SGEDataset(raw_dir='/shareN/data8/SwapTmp/fy/Spatial/ARGA-ARVGA/SGE2/raw',id=sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-15\n",
    "sample_id = list(range(151507, 151511)) + list(range(151669, 151677))\n",
    "SGE_train = SGEDataset1(root='/shareN/data8/SwapTmp/fy/Spatial/ARGA-ARVGA/', name='SGE2', id=sample_id)\n",
    "SGE_test = SGEDataset1(root='/shareN/data8/SwapTmp/fy/Spatial/ARGA-ARVGA/', name='SGE2', id=sample_id)\n",
    "train_loader = DataLoader(SGE_train[0,2,4,6,8,10], batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(SGE_train[1,3,5,7,9,11], batch_size=1, shuffle=False)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(num_nodes, train_ratio=0.8):\n",
    "    mask = torch.rand(num_nodes) < train_ratio\n",
    "    return mask\n",
    "\n",
    "data = data.to(device)  # 假设这是你的图数据\n",
    "num_nodes = data.x.size(0)\n",
    "\n",
    "train_mask = create_mask(num_nodes).to(device)\n",
    "test_mask = ~train_mask\n",
    "\n",
    "train_data = data.clone()  # 创建数据的副本\n",
    "test_data = data.clone()\n",
    "\n",
    "# # 更新节点信息\n",
    "train_data.x = data.x[train_mask]\n",
    "test_data.x = data.x[test_mask]\n",
    "\n",
    "# # 更新边信息\n",
    "train_edge_mask = train_mask[data.edge_index[0]] & train_mask[data.edge_index[1]]\n",
    "test_edge_mask = test_mask[data.edge_index[0]] & test_mask[data.edge_index[1]]\n",
    "\n",
    "train_data.edge_index = data.edge_index[:, train_edge_mask]\n",
    "test_data.edge_index = data.edge_index[:, test_edge_mask]\n",
    "\n",
    "# # 根据需要更新其他属性\n",
    "train_data.x= data.x\n",
    "test_data.x = data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = torch.Tensor(2, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nv, N = SGE_train[0].x.size() \n",
    "# Nv, N = d[0].x.size() \n",
    "# Nv2, N = SGE_train[0][1].x.size()   \n",
    "# ppi = pandas.read_csv('/shareN/data8/SwapTmp/fy/Spatial/ARGA-ARVGA/GBM/PPI.connect.txt', sep=' ', header=0)\n",
    "ppi = pandas.read_csv('/shareN/data8/SwapTmp/fy/Spatial/ARGA-ARVGA/SGE2/PPI.connect.txt', sep=' ', header=None)\n",
    "con = ppi.values[:, range(1,3)].transpose()\n",
    "con = torch.tensor(con.astype(int), dtype=torch.long)\n",
    "M = con.shape[1]\n",
    "# emd = pandas.read_csv('/shareN/data8/SwapTmp/fy/Spatial/ARGA-ARVGA/emd_8_samples.txt',sep = '\\t', header=0)\n",
    "# emd = torch.tensor(emd.values)[:, [6, 0, 1, 2, 3, 4, 5]]\n",
    "# emd = emd[[6, 0, 1, 2, 3, 4, 5]]\n",
    "# #K_empiric = torch.exp(-5E2 * torch.log(emd / 4))\n",
    "# K_empiric = torch.exp(-18.5 * torch.log(emd / 4))\n",
    "# K_sparse = dense_to_sparse(K_empiric)\n",
    "# edge_pos = K_sparse[0][:, K_sparse[1] > .5]\n",
    "# edge_pos = edge_pos.to(device)\n",
    "# edge_neg = K_sparse[0][:, K_sparse[1] < .5]\n",
    "# edge_neg = edge_neg.to(device)\n",
    "# edge_weight = K_sparse[1][K_sparse[1] > .5]\n",
    "# edge_weight = edge_weight.to(device)\n",
    "con1 = torch.tensor([numpy.arange(0,N),numpy.arange(0,N)])\n",
    "con = torch.cat([con,con1],dim = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import e\n",
    "import numpy\n",
    "import torch\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.distributions.kl import kl_divergence\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, Dropout, ReLU, LeakyReLU, Softmax, Parameter\n",
    "from sparselinear import SparseLinear\n",
    "from torch_geometric.nn import MessagePassing, knn_graph, DMoNPooling, GINConv, EdgePooling, GraphNorm, MessageNorm\n",
    "from torch_geometric.utils import erdos_renyi_graph, unbatch, to_dense_adj, to_dense_batch, dense_to_sparse, remove_self_loops, add_remaining_self_loops\n",
    "from scripts.sqrtm import sqrtm\n",
    "from scripts.CustomFunc import scale, dropout_edge\n",
    "from scripts.SGWTConv import SGWTConv\n",
    "\n",
    "\n",
    "class ResNet(torch.nn.Module):\n",
    "    def __init__(self, module):\n",
    "        super().__init__()\n",
    "        self.module = module\n",
    "    def forward(self, inputs):\n",
    "        return self.module(inputs) + inputs\n",
    "\n",
    "'''\n",
    "class ResNet(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.module = Sequential(\n",
    "                    Linear(in_channels, hidden_channels),\n",
    "                    LeakyReLU(0.1),\n",
    "                    Linear(hidden_channels, in_channels)\n",
    "                ) \n",
    "    def forward(self, inputs):\n",
    "        return self.module(inputs) + inputs\n",
    "'''\n",
    "\n",
    "class FixedSparseEdgeConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, connect):\n",
    "        super().__init__(aggr='max') #  \"Maximum\" aggregation.\n",
    "        self.out_dim = out_channels\n",
    "        self.lin1 = SparseLinear(2 * in_channels, in_channels, connectivity=connect)\n",
    "        self.lin2 = Linear(in_channels, out_channels)\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        return self.propagate(edge_index, x=x, edge_weight=edge_weight)\n",
    "    def message(self, x_i, x_j, edge_weight):\n",
    "        out = torch.cat([x_i, x_j], dim=1) \n",
    "        # print(out.shape)\n",
    "        out = F.relu(self.lin1(out)) + x_i\n",
    "        out = self.lin2(out)\n",
    "        # print(out)\n",
    "        # print(out.shape)\n",
    "        n_h = edge_weight.size(1)   \n",
    "        s_h = self.out_dim // n_h   \n",
    "        out = torch.matmul(out.view(-1, s_h, n_h), edge_weight) \n",
    "        # print(out.shape)\n",
    "        # print(out.view(-1, n_h * s_h).shape)\n",
    "        return out.view(-1, n_h * s_h)\n",
    "\n",
    "class FullEdgeConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='mean') #  \"Mean\" aggregation.\n",
    "        self.out_dim = out_channels\n",
    "        self.lin1 = Linear(2 * in_channels, in_channels)\n",
    "        self.lin2 = Linear(in_channels, out_channels)\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        return self.propagate(edge_index, x=x, edge_weight=edge_weight)\n",
    "    def message(self, x_i, x_j, edge_weight):\n",
    "        out = torch.cat([x_i, x_j], dim=1) \n",
    "        out = F.relu(self.lin1(out)) + x_i\n",
    "        out = self.lin2(out)\n",
    "        n_h = edge_weight.size(1)   \n",
    "        s_h = self.out_dim // n_h   \n",
    "        out = torch.matmul(out.view(-1, s_h, n_h), edge_weight) \n",
    "        return out.view(-1, n_h * s_h)\n",
    "\n",
    "class PPIEdgeConv(FixedSparseEdgeConv):\n",
    "    def __init__(self, in_channels, out_channels, connect, pi=None, dropout=None, k=None, n_heads=2):\n",
    "        super().__init__(in_channels, out_channels, connect)\n",
    "        self.pi = pi\n",
    "        self.dropout = dropout\n",
    "        self.k = k\n",
    "        self.n_heads = n_heads\n",
    "        self.head_size = out_channels // n_heads\n",
    "        self.d_k = out_channels\n",
    "        self.qnet = Sequential(\n",
    "                        SparseLinear(2 * in_channels, in_channels, connectivity=connect),\n",
    "                        Linear(in_channels, out_channels),\n",
    "                    )\n",
    "        self.knet = Sequential(\n",
    "                        SparseLinear(2 * in_channels, in_channels, connectivity=connect),\n",
    "                        Linear(in_channels, out_channels),\n",
    "                    )\n",
    "    def reshape(self, e):\n",
    "        new_shape = e.size()[:-1] + (self.n_heads, self.head_size)\n",
    "        e = e.view(*new_shape)\n",
    "        return e\n",
    "    def forward(self, x, edge_index, batch=None):    \n",
    "        if self.k is None:\n",
    "            n = x.size(0)  \n",
    "            edge_index = torch.zeros(2, 0, dtype=torch.long, device=x.device)\n",
    "            for v in unbatch(torch.arange(n, device=x.device), batch):\n",
    "                e = erdos_renyi_graph(n, self.pi, directed=False)\n",
    "                e = e.to(x.device)\n",
    "                edge_index = torch.cat([edge_index, v[e]], dim=1)                   \n",
    "        if self.pi is None:\n",
    "            edge_index = knn_graph(x, self.k, batch, loop=False, flow=self.flow)    \n",
    "        edge_index, _ = remove_self_loops(edge_index)\n",
    "        edge_index, _ = dropout_edge(edge_index, self.dropout, force_undirected=True)\n",
    "        x_src, x_dst = x[edge_index]\n",
    "        Q = self.qnet(torch.cat([x_src, x_dst], dim=1))\n",
    "        K = self.knet(torch.cat([x_src, x_dst], dim=1))\n",
    "        Q = self.reshape(Q)\n",
    "        K = self.reshape(K)\n",
    "        edge_weight = torch.matmul(Q, K.permute(0, 2, 1)) / torch.tensor(self.d_k).sqrt()\n",
    "        return super().forward(x, edge_index, edge_weight)\n",
    "\n",
    "class DynamicEdgeConv(FullEdgeConv):\n",
    "    def __init__(self, in_channels, out_channels, k=4, dropout=0.0, n_heads=2):\n",
    "        super().__init__(in_channels, out_channels)\n",
    "        self.k = k\n",
    "        self.dropout = dropout\n",
    "        self.n_heads = n_heads\n",
    "        self.head_size = out_channels // n_heads\n",
    "        self.d_k = out_channels\n",
    "        self.qnet = Linear(2 * in_channels, out_channels)\n",
    "        self.knet = Linear(2 * in_channels, out_channels)\n",
    "    def reshape(self, e):\n",
    "        new_shape = e.size()[:-1] + (self.n_heads, self.head_size)\n",
    "        e = e.view(*new_shape)\n",
    "        return e    \n",
    "    def forward(self, x, edge_index, batch=None):\n",
    "        edge_index = knn_graph(x, self.k, batch, loop=False, flow=self.flow)\n",
    "        edge_index, _ = dropout_edge(edge_index, self.dropout, force_undirected=True)\n",
    "        x_src, x_dst = x[edge_index]\n",
    "        Q = self.qnet(torch.cat([x_src, x_dst], dim=1)) \n",
    "        K = self.knet(torch.cat([x_src, x_dst], dim=1))\n",
    "        Q = self.reshape(Q)\n",
    "        K = self.reshape(K)\n",
    "        edge_weight = torch.matmul(Q, K.permute(0, 2, 1)) / torch.tensor(self.d_k).sqrt()\n",
    "        return super().forward(x, edge_index, edge_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STx_encoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, m, l, connect, pi, n_heads, K):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.n_heads = n_heads\n",
    "        self.conv0 = SGWTConv(in_channels, hidden_channels, K)\n",
    "        self.norm1 = GraphNorm(hidden_channels)\n",
    "        self.conv1 = SGWTConv(in_channels + hidden_channels, hidden_channels, K)\n",
    "        self.fc1 = Sequential(\n",
    "                            Linear(hidden_channels, m * 16),\n",
    "                            SELU(),\n",
    "                            Linear(m * 16, m * 4),\n",
    "                            SELU(),\n",
    "                            Linear(m * 4, m)\n",
    "                            )\n",
    "        self.conv2 = PPIEdgeConv(in_channels, hidden_channels, connect, pi=pi, k=None, dropout=0.0, n_heads=self.n_heads)   \n",
    "        self.conv3 = DynamicEdgeConv(hidden_channels, hidden_channels, k=3, dropout=0.1, n_heads=self.n_heads)\n",
    "        self.fc2 = Sequential(\n",
    "                            # Linear(hidden_channels, hidden_channels // 2),  \n",
    "                            Linear(in_channels, hidden_channels // 2),\n",
    "                            SELU(),\n",
    "                            Linear(hidden_channels // 2, hidden_channels // 4),\n",
    "                            SELU(),                 \n",
    "                            Linear(hidden_channels // 4, out_channels)\n",
    "                            ) \n",
    "        self.fc3 = Sequential(\n",
    "                            # Linear(hidden_channels, hidden_channels * 2),  \n",
    "                            Linear(in_channels, hidden_channels // 2),\n",
    "                            SELU(),\n",
    "                            Linear(hidden_channels * 2, hidden_channels * 4),\n",
    "                            SELU(),                 \n",
    "                            Linear(hidden_channels * 4, out_channels * l)\n",
    "                            )               \n",
    "    def forward(self, x,edge_index,edge_weight, batch, mask: Optional[torch.Tensor] = None):\n",
    "        edge_index = knn_graph(x, 3, batch, loop=False) if edge_index is None else edge_index\n",
    "        u = self.conv0(x, edge_index, edge_weight, batch)\n",
    "        u = self.norm1(u, batch)\n",
    "        # u = torch.cat((x, u), dim = 1)\n",
    "        # edge_index = knn_graph(u, 3, batch, loop=False)\n",
    "        # u = self.conv1(u, edge_index, edge_weight, batch)\n",
    "        u = self.fc1(u)\n",
    "        S = u.softmax(dim=-1)\n",
    "        S = S.unsqueeze(0) if S.dim() == 2 else S\n",
    "        x, _ = to_dense_batch(x, batch)  \n",
    "        (batch_size, num_nodes, _) = x.size() \n",
    "        if mask is not None:\n",
    "            mask = mask.view(batch_size, num_nodes, 1).to(x.dtype)\n",
    "            x, S = x * mask, S * mask\n",
    "        x = torch.matmul(S.transpose(1, 2), x)\n",
    "        x = x.transpose(1, 2) / torch.sum(S, dim=1, keepdim=True).clamp(min=1.)\n",
    "        # batch = torch.tensor(range(S.size(0)), dtype=torch.float32, device=S.device)\n",
    "        batch = torch.tensor(range(S.size(0)), device=S.device)\n",
    "        batch = batch.repeat_interleave(S.size(2))        \n",
    "        x = x.view(-1, x.size(2)).t()\n",
    "        S = S.view(-1, S.size(2))\n",
    "        mu = x\n",
    "        # x = self.conv2(x, _, batch)\n",
    "        # y = self.conv3(x, _, batch)\n",
    "        # z = x + y\n",
    "        return u, mu, self.fc2(x), self.fc3(x), edge_index, batch\n",
    "\n",
    "\n",
    "class STx_discriminator(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(54321)\n",
    "        self.conv = GINConv(Sequential(\n",
    "                                        Linear(in_channels, hidden_channels),\n",
    "                                        SELU(),\n",
    "                                        Linear(hidden_channels, hidden_channels)\n",
    "                            ))\n",
    "        self.fc = Sequential(\n",
    "                            Linear(hidden_channels, hidden_channels // 3),  \n",
    "                            SELU(),\n",
    "                            Linear(hidden_channels // 3, out_channels)                 \n",
    "                            )\n",
    "    def forward(self, z, edge_index, batch):        \n",
    "        edge_index = knn_graph(z, 4, batch, loop=False) if edge_index is None else edge_index\n",
    "        z = self.conv(z, edge_index)\n",
    "        z = self.fc(z)\n",
    "        return z\n",
    " \n",
    " \n",
    "class STx_ARGA(GAE):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder: Module,\n",
    "        discriminator: Module,\n",
    "        decoder: Optional[Module] = None,\n",
    "    ):\n",
    "        super().__init__(encoder, decoder)\n",
    "        self.discriminator = discriminator   \n",
    "        self.criterion = CrossEntropyLoss()     \n",
    "        reset(self.discriminator)   \n",
    "    # def recon_loss(self, z: torch.Tensor,\n",
    "    #             pos_edge_index: torch.Tensor, \n",
    "    #             pos_edge_weight: torch.Tensor,\n",
    "    #             # pos_edge_weight: Optional[torch.Tensor] = None,\n",
    "    #             neg_edge_index: torch.Tensor) -> torch.Tensor:\n",
    "    #             # neg_edge_index: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "    #     pos_pred = self.decoder(z, pos_edge_index, sigmoid=True)\n",
    "    #     if pos_edge_weight is None:\n",
    "    #         pos_edge_weight = torch.ones_like(pos_pred, dtype=torch.float32)\n",
    "    #     pos_loss = ((pos_edge_weight - pos_pred) ** 2).mean()\n",
    "    #     if neg_edge_index is None:\n",
    "    #         neg_edge_index = negative_sampling(pos_edge_index, z.size(0))\n",
    "    #     neg_pred = self.decoder(z, neg_edge_index, sigmoid=True)\n",
    "    #     neg_loss = (neg_pred ** 2).mean() \n",
    "    #     return pos_loss + neg_loss                     \n",
    "    def recon_loss(self, z: torch.Tensor, \n",
    "                pos_edge_index: torch.Tensor,   \n",
    "                neg_edge_index: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        pos_loss = -torch.log( self.decoder(z, pos_edge_index, sigmoid=True) + EPS).mean() \n",
    "        if neg_edge_index is None: \n",
    "            neg_edge_index = negative_sampling(pos_edge_index, z.size(0))\n",
    "            neg_edge_index, _ = remove_self_loops(neg_edge_index)\n",
    "        neg_loss = -torch.log(1 - self.decoder(z, neg_edge_index, sigmoid=True) + EPS).mean() \n",
    "        return pos_loss + neg_loss       \n",
    "    def reset_parameters(self):\n",
    "        super().reset_parameters()\n",
    "        reset(self.discriminator)\n",
    "    def reg_loss(self, z: torch.Tensor, edge_index: torch.Tensor, batch: torch.Tensor) -> torch.Tensor:\n",
    "        real = torch.sigmoid(self.discriminator(z, edge_index, batch))\n",
    "        real_loss = -torch.log(real + EPS).mean()\n",
    "        return real_loss\n",
    "    def discriminator_loss(self, z: torch.Tensor, edge_index: torch.Tensor, batch: torch.Tensor) -> torch.Tensor:\n",
    "        real = torch.sigmoid(self.discriminator(torch.randn_like(z), edge_index, batch))\n",
    "        fake = torch.sigmoid(self.discriminator(z.detach(), edge_index, batch))\n",
    "        real_loss = -torch.log(real + EPS).mean()\n",
    "        fake_loss = -torch.log(1 - fake + EPS).mean()\n",
    "        return real_loss + fake_loss\n",
    " \n",
    "class STx_ARGVA(STx_ARGA):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder: Module,\n",
    "        discriminator: Module,\n",
    "        decoder: Optional[Module] = None,\n",
    "        l: Optional[torch.Tensor] = 1,\n",
    "    ):\n",
    "        super().__init__(encoder, discriminator, decoder) \n",
    "        self.l = l     \n",
    "    def reparameterize(self, s: torch.Tensor, mu: torch.Tensor, A: torch.Tensor) -> torch.Tensor:\n",
    "        # z = torch.matmul(s, mu)\n",
    "        z = torch.matmul(s, mu.sigmoid())\n",
    "        if self.training:\n",
    "            C = torch.Tensor(onehot_to_label(s.t().cpu()).values).int().view(-1) \n",
    "            z = torch.cat([\n",
    "                    torch.matmul(torch.randn(1, self.l, device=mu.device), A[C[i]].view(self.l, -1)) \n",
    "                        for i in range(s.size(0))\n",
    "                    ]) + z\n",
    "        return z    \n",
    "    def encode(self, s: torch.Tensor, \n",
    "                    x: torch.Tensor, \n",
    "                    edge_index: torch.Tensor, \n",
    "                    edge_weight: torch.Tensor,\n",
    "                    batch: torch.Tensor, \n",
    "                    mask: torch.Tensor) -> torch.Tensor:\n",
    "        self.__u__, self.__m__, self.__v__, self.__A__, self.__e__, self.__b__ = self.encoder(x, edge_index, edge_weight, batch, mask)\n",
    "        self.__A__ = self.__A__.clamp(min=MIN, max=MAX)\n",
    "        self.__logstd__ =  torch.cat([\n",
    "                        torch.matmul(self.__A__[i].view(self.l, -1).t(), self.__A__[i].view(self.l, -1)).diag().view(1, -1)\n",
    "                            for i in range(self.__m__.size(0))\n",
    "                        ]).log() \n",
    "        S = self.__u__.softmax(dim=-1)\n",
    "        self.__adj__ = to_dense_adj(self.__e__)  \n",
    "        self.__adj1__ = torch.matmul(torch.matmul(S.t(), self.__adj__), S)   \n",
    "        s = S if s is None else s   \n",
    "        z = self.reparameterize(s, self.__v__, self.__A__)\n",
    "        return z, self.__b__ \n",
    "    def cluster_loss(self, u: torch.Tensor, y: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        u = self.__u__ if u is None else u\n",
    "        k = u.size(1)\n",
    "        s = u.softmax(dim=-1)\n",
    "        degrees = torch.einsum('ijk->ik', self.__adj__).t()\n",
    "        m = torch.einsum('ij->', degrees)\n",
    "        ca = torch.matmul(s.t(), degrees)\n",
    "        cb = torch.matmul(degrees.t(), s)\n",
    "        normalizer = torch.matmul(ca, cb) / 2 / m\n",
    "        decompose = self.__adj1__ - normalizer\n",
    "        spectral_loss = -_rank3_trace(decompose) / 2 / m\n",
    "        spectral_loss = torch.mean(spectral_loss)\n",
    "        # Orthogonal loss\n",
    "        ss = torch.matmul(s.t(), s)\n",
    "        i_s = torch.eye(k).type_as(ss)\n",
    "        ortho_loss = torch.norm(\n",
    "            ss / torch.norm(ss, dim=(-1, -2), keepdim=True) - i_s / torch.norm(i_s), dim=(-1, -2))\n",
    "        ortho_loss = torch.mean(ortho_loss) \n",
    "        # Cluster loss:\n",
    "        cluster_loss = torch.norm(torch.einsum('ij->i', ss)) / self.__adj__.size(1) * torch.norm(i_s) - 1  \n",
    "        out = cluster_loss + ortho_loss + spectral_loss if y is None else cluster_loss + ortho_loss + spectral_loss + F.cross_entropy(u, y)        \n",
    "        return out\n",
    "    def kl_loss(\n",
    "        self,\n",
    "        mu: Optional[torch.Tensor] = None,\n",
    "        logstd: Optional[torch.Tensor] = None,\n",
    "    ) -> torch.Tensor:\n",
    "        mu = self.__v__ if mu is None else mu\n",
    "        logstd = self.__logstd__ if logstd is None else logstd.clamp(max=MAX_LOGSTD)\n",
    "        return -0.5 * torch.mean(\n",
    "            torch.sum(1 + 2 * logstd - mu**2 - logstd.exp()**2, dim=1))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics  import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def cal_auc_ap_acc(sampling_n, edge_index,z,adj):\n",
    "    auroc = []\n",
    "    ap_score = []\n",
    "    acc_score = []\n",
    "    preds = []\n",
    "    pos = []\n",
    "    preds = []\n",
    "    for src, dst in zip(edge_index[0], edge_index[1]):\n",
    "        preds.append(adj[src, dst].item())\n",
    "    preds = torch.tensor(preds).to(device)\n",
    "    for i in range(sampling_n):\n",
    "        neg_edge_index = negative_sampling(edge_index=edge_index, num_nodes=z.size(0))\n",
    "        neg_edge_index, _ = remove_self_loops(neg_edge_index)\n",
    "        preds_neg = []\n",
    "        for src1, dst1 in zip(neg_edge_index[0], neg_edge_index[1]):\n",
    "            preds_neg.append(adj[src1, dst1].item())\n",
    "        preds_neg = torch.tensor(preds_neg).to(device)\n",
    "        preds_all = torch.cat([preds, preds_neg],dim=0)\n",
    "        labels_all = torch.cat([torch.ones(len(preds)), torch.zeros(len(preds_neg))])\n",
    "        # # labels_all = torch.cat([torch.ones(len(preds_neg)), torch.zeros(len(preds))])\n",
    "        labels_all = labels_all.detach().cpu()\n",
    "        preds_all = preds_all.detach().cpu()\n",
    "        roc_score = roc_auc_score(labels_all, preds_all)\n",
    "        auroc.append(roc_score.item())\n",
    "        ap = average_precision_score(labels_all, preds_all)\n",
    "        ap_score.append(ap)\n",
    "        acc = accuracy_score(labels_all, numpy.round(preds_all))\n",
    "        acc_score.append(acc)\n",
    "    return auroc,ap_score,acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels=N\n",
    "hidden_channels=96\n",
    "out_channels=16\n",
    "m=7\n",
    "l=3\n",
    "K=3\n",
    "connect=con\n",
    "pi=0.75\n",
    "n_heads=8\n",
    "n_heads = n_heads\n",
    "conv0 = SGWTConv(in_channels, hidden_channels, K).to(device)\n",
    "norm1 = GraphNorm(hidden_channels).to(device)\n",
    "conv1 = SGWTConv(in_channels + hidden_channels, hidden_channels, K).to(device)\n",
    "fc1 = Sequential(\n",
    "                            Linear(hidden_channels, m * 16),\n",
    "                            SELU(),\n",
    "                            Linear(m * 16, m * 4),\n",
    "                            SELU(),\n",
    "                            Linear(m * 4, m)\n",
    "                            ).to(device)\n",
    "conv2 = PPIEdgeConv(in_channels, hidden_channels, connect, pi=pi, k=None, dropout=0.0, n_heads=n_heads).to(device)   \n",
    "conv3 = DynamicEdgeConv(hidden_channels, hidden_channels, k=3, dropout=0.1, n_heads=n_heads).to(device)\n",
    "fc2 = Sequential(\n",
    "                            Linear(hidden_channels, hidden_channels // 2),  \n",
    "                            SELU(),\n",
    "                            Linear(hidden_channels // 2, hidden_channels // 4),\n",
    "                            SELU(),                 \n",
    "                            Linear(hidden_channels // 4, out_channels)\n",
    "                            ).to(device) \n",
    "fc3 = Sequential(\n",
    "                            Linear(hidden_channels, hidden_channels * 2),  \n",
    "                            SELU(),\n",
    "                            Linear(hidden_channels * 2, hidden_channels * 4),\n",
    "                            SELU(),                 \n",
    "                            Linear(hidden_channels * 4, out_channels * l)\n",
    "                            ).to(device)              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[1817, 1869], edge_index=[2, 5362], y=[1817], edge_weight=[5362], batch=[1817])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "scatter(): Expected dtype int64 for index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m  data\u001b[38;5;241m.\u001b[39medge_index\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# edge_mask = torch.bernoulli(torch.ones(edge_index.shape[1]) * 0.9)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# indices_one = torch.nonzero(edge_mask, as_tuple=True)[0]\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# edge_index = edge_index[:,indices_one]\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# # edge_index = knn_graph(x, 3, batch, loop=False) if edge_index is None else edge_index\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m u \u001b[38;5;241m=\u001b[39m \u001b[43mconv0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# u = norm1(u, None)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# u = torch.cat((x, u), dim = 1)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# # # edge_index = knn_graph(u, 3, batch, loop=False)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# z = x + y\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# return u, mu, self.fc2(z), self.fc3(z), edge_index, batch\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/geometric2/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/shareN/data8/SwapTmp/fy/Spatial/ARGA-ARVGA/scripts/SGWTConv.py:120\u001b[0m, in \u001b[0;36mSGWTConv.forward\u001b[0;34m(self, x, edge_index, edge_weight, batch, lambda_max)\u001b[0m\n\u001b[1;32m    109\u001b[0m edge_index, norm, lambda_max, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__norm__(\n\u001b[1;32m    110\u001b[0m     edge_index,\n\u001b[1;32m    111\u001b[0m     x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m     batch\u001b[38;5;241m=\u001b[39mbatch,\n\u001b[1;32m    117\u001b[0m )\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m     L \u001b[38;5;241m=\u001b[39m \u001b[43mto_dense_adj\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m     L \u001b[38;5;241m=\u001b[39m to_dense_adj(edge_index, edge_attr\u001b[38;5;241m=\u001b[39mnorm)\n",
      "File \u001b[0;32m~/.conda/envs/geometric2/lib/python3.11/site-packages/torch_geometric/utils/to_dense_adj.py:72\u001b[0m, in \u001b[0;36mto_dense_adj\u001b[0;34m(edge_index, batch, edge_attr, max_num_nodes, batch_size)\u001b[0m\n\u001b[1;32m     69\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(batch\u001b[38;5;241m.\u001b[39mmax()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     71\u001b[0m one \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mnew_ones(batch\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m---> 72\u001b[0m num_nodes \u001b[38;5;241m=\u001b[39m \u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m cum_nodes \u001b[38;5;241m=\u001b[39m cumsum(num_nodes)\n\u001b[1;32m     75\u001b[0m idx0 \u001b[38;5;241m=\u001b[39m batch[edge_index[\u001b[38;5;241m0\u001b[39m]]\n",
      "File \u001b[0;32m~/.conda/envs/geometric2/lib/python3.11/site-packages/torch_geometric/utils/scatter.py:70\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     69\u001b[0m     index \u001b[38;5;241m=\u001b[39m broadcast(index, src, dim)\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_zeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter_add_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     73\u001b[0m     count \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mnew_zeros(dim_size)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: scatter(): Expected dtype int64 for index"
     ]
    }
   ],
   "source": [
    "data = d[0].to(device)\n",
    "x = data.x\n",
    "src_mask = torch.bernoulli(torch.ones(data.x.size(0)) * 0.9).to(device)\n",
    "# # x = (data.x+1).log().to(device)\n",
    "# # z, _ = model.encode(None, data.x, data.edge_index,data.edge_weight, data.batch, src_mask)\n",
    "edge_index =  data.edge_index\n",
    "# edge_mask = torch.bernoulli(torch.ones(edge_index.shape[1]) * 0.9)\n",
    "# indices_one = torch.nonzero(edge_mask, as_tuple=True)[0]\n",
    "# edge_index = edge_index[:,indices_one]\n",
    "# # edge_index = knn_graph(x, 3, batch, loop=False) if edge_index is None else edge_index\n",
    "u = conv0(x, edge_index, None, data.batch)\n",
    "# u = norm1(u, None)\n",
    "# u = torch.cat((x, u), dim = 1)\n",
    "# # # edge_index = knn_graph(u, 3, batch, loop=False)\n",
    "# u = conv1(u, edge_index, None, None)\n",
    "# u = fc1(u)\n",
    "# S = u.softmax(dim=-1)\n",
    "# S = S.unsqueeze(0) if S.dim() == 2 else S\n",
    "# x, _ = to_dense_batch(x, None)  \n",
    "# (batch_size, num_nodes, _) = x.size() \n",
    "# # if mask is not None:\n",
    "# #     mask = mask.view(batch_size, num_nodes, 1).to(x.dtype)\n",
    "# #     x, S = x * mask, S * mask\n",
    "# x = torch.matmul(S.transpose(1, 2), x)\n",
    "# x = x.transpose(1, 2) / torch.sum(S, dim=1, keepdim=True).clamp(min=1.)\n",
    "# # # batch = torch.tensor(range(S.size(0)), dtype=torch.float32, device=S.device)\n",
    "# batch = torch.tensor(range(S.size(0)), device=S.device)\n",
    "# batch = batch.repeat_interleave(S.size(2))        \n",
    "# x = x.view(-1, x.size(2)).t()\n",
    "# S = S.view(-1, S.size(2))\n",
    "# mu = x\n",
    "# x = conv2(x, _, batch)\n",
    "# print(x.shape)\n",
    "# y = conv3(x, _, batch)\n",
    "# print(y.shape)\n",
    "# z = x + y\n",
    "# return u, mu, self.fc2(z), self.fc3(z), edge_index, batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader):\n",
    "    model.train()\n",
    "    l2_lambda = 0.001\n",
    "    running_loss = 0\n",
    "    print(\"train\")\n",
    "    # for data in loader: # Iterate in batches over the training dataset.\n",
    "    data = loader.to(device)\n",
    "    s = data.x.shape[0]\n",
    "    src_mask = torch.bernoulli(torch.ones(data.x.size(0)) * 0.9).to(device)\n",
    "    # x = (data.x+1).log().to(device)\n",
    "    # z, _ = model.encode(None, data.x, data.edge_index,data.edge_weight, data.batch, src_mask)\n",
    "    edge_index =  data.edge_index\n",
    "    edge_mask = torch.bernoulli(torch.ones(edge_index.shape[1]) * 0.9)\n",
    "    indices_one = torch.nonzero(edge_mask, as_tuple=True)[0]\n",
    "    edge_index = edge_index[:,indices_one]\n",
    "    z, _ = model.encode(None, data.x, edge_index,None, None, src_mask)\n",
    "    w = model.__u__\n",
    "    cl = w.cpu().softmax(dim=-1)\n",
    "    for _ in range(5):\n",
    "        discriminator.train()\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        discriminator_loss = model.discriminator_loss(z, edge_index, None)\n",
    "        discriminator_loss.backward(retain_graph=True)\n",
    "        discriminator_optimizer.step()\n",
    "    loss = 0\n",
    "    clast_loss = 0\n",
    "    loss = loss + model.reg_loss(z, None, None)\n",
    "    loss = loss + model.recon_loss(z, edge_index, None)\n",
    "    loss = loss + model.cluster_loss(None, data.y)\n",
    "    loss = loss + (1 / data.num_nodes) * model.kl_loss()\n",
    "    reg_loss =  model.reg_loss(z, None, None)\n",
    "    recon_loss = model.recon_loss(z, edge_index,None)\n",
    "    clast_loss = model.cluster_loss(None, data.y)\n",
    "    l2_regularization = torch.tensor(0., requires_grad=True, device=device)\n",
    "    for name, param in model.encoder.named_parameters():\n",
    "        if 'bias' not in name:\n",
    "            l2_regularization = l2_regularization + torch.norm(param, p=1)\n",
    "    loss = loss + l2_lambda * l2_regularization\n",
    "    clip_grad_value_(model.encoder.parameters(), .1)\n",
    "    encoder_optimizer.step()\n",
    "    encoder_optimizer.zero_grad()\n",
    "    running_loss += loss.item()\n",
    "    loss.backward()\n",
    "    ari1 = adjusted_rand_score(onehot_to_label(cl.t()).values.reshape(-1), data.y.cpu())\n",
    "    acc1 = accuracy_score(data.y.cpu(), onehot_to_label(cl.t()).values.reshape(-1))\n",
    "    nmi1 =  normalized_mutual_info_score(data.y.cpu(), onehot_to_label(cl.t()).values.reshape(-1))\n",
    "    adj = model.decoder.forward_all(z)\n",
    "    auroc,ap_score,acc_score = cal_auc_ap_acc(1,data.edge_index,z,adj)\n",
    "    auc = np.mean(auroc)\n",
    "    ap = np.mean(ap_score)\n",
    "    acc = np.mean(acc_score)\n",
    "    f.write( ','.join(map(str, torch.tensor([epoch, loss, reg_loss, recon_loss, clast_loss,ari1, acc1, nmi1,auc,ap,acc,s]).numpy())))\n",
    "    f.write('\\n')\n",
    "    print((f'Epoch: {epoch:03d}, Loss: {loss:.3f}, loss reg: {reg_loss:.3f}, '\n",
    "            f'loss recon: {recon_loss:.3f}, '\n",
    "        f'loss class: {clast_loss:.3f}, '\n",
    "        f'ARI: {ari1:.3f},'\n",
    "        f'ACC: {acc1:.3f},'\n",
    "        f'NMI: {nmi1:.3f},'\n",
    "        f'AUC: {auc:.3f},'\n",
    "        f'AP: {ap:.3f},'\n",
    "        f'ACC1: {acc:.3f},'\n",
    "        f'Shape: {s}'))\n",
    "    encoder_optimizer.step()\n",
    "    encoder_optimizer.zero_grad()\n",
    "    running_loss += loss.item()\n",
    "    return running_loss / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    print(\"test\")\n",
    "    model.eval()\n",
    "    loss_reg = 0\n",
    "    loss_clust = 0\n",
    "    loss_recon = 0\n",
    "    loss_recon1 = 0\n",
    "    loss_clust1 = 0\n",
    "    # for data in loader: # Iterate in batches over the training/test dataset.\n",
    "    data = loader.to(device)\n",
    "    # x = (data.x+1).log().to(device)\n",
    "    # z, _ = model.encode(None, data.x, data.edge_index,None, data.batch, None)\n",
    "    z, _ = model.encode(None, data.x, data.edge_index,None, None, None)\n",
    "    loss_reg =  model.reg_loss(z, None, None)\n",
    "    loss_recon = model.recon_loss(z, data.edge_index, None)\n",
    "    loss_clust =  model.cluster_loss(None, data.y)\n",
    "    # loss_clust = 0\n",
    "    # loss_recon1 = loss_recon1 + model.recon_loss(z, data.edge_index, None)\n",
    "    loss_clust1 = loss_clust1 + model.recon_loss(z, data.edge_index, None)\n",
    "    w = model.__u__\n",
    "    cl = w.cpu().softmax(dim=-1)\n",
    "    s = data.x.shape[0]\n",
    "    ari = adjusted_rand_score(onehot_to_label(cl.t()).values.reshape(-1), data.y.cpu())\n",
    "    acc = accuracy_score(data.y.cpu(), onehot_to_label(cl.t()).values.reshape(-1))\n",
    "    nmi =  normalized_mutual_info_score(data.y.cpu(), onehot_to_label(cl.t()).values.reshape(-1))\n",
    "    # ami = adjusted_mutual_info_score(data.y.cpu(), onehot_to_label(cl.t()).values.reshape(-1))\n",
    "    # print(ari)\n",
    "    # loss = 0\n",
    "    adj = model.decoder.forward_all(z)\n",
    "    auroc,ap_score,acc_score = cal_auc_ap_acc(1,data.edge_index,z,adj)\n",
    "    auc = np.mean(auroc)\n",
    "    ap = np.mean(ap_score)\n",
    "    acc1 = np.mean(acc_score)\n",
    "    f1.write( ','.join(map(str, torch.tensor([epoch, loss, loss_reg,loss_recon, loss_clust,ari,acc,nmi,auc,ap,acc,s]).numpy())))\n",
    "    f1.write('\\n')\n",
    "        # print(\"test\")\n",
    "    print((f'Epoch: {epoch:03d}, Loss: {loss:.3f}, loss reg: {loss_reg:.3f}, '\n",
    "            f'loss recon: {loss_recon:.3f}, '\n",
    "        f'loss class: {loss_clust:.3f}, '\n",
    "        f'ARI: {ari:.3f},'\n",
    "        f'ACC: {acc:.3f},'\n",
    "        f'NMI: {nmi:.3f},'\n",
    "        f'AUC: {auc:.3f},'\n",
    "        f'AP: {ap:.3f},'\n",
    "        f'ACC1: {acc1:.3f},'\n",
    "        f'Shape: {s}'))\n",
    "    return loss_reg , loss_clust, loss_recon,auc # Derive ratio of correct predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = STx_encoder(in_channels=N,\n",
    "              hidden_channels=96,\n",
    "              out_channels=16,\n",
    "              m=7, l=3, K=3,\n",
    "              connect=con, pi=0.75, n_heads=8)\n",
    "discriminator = STx_discriminator(in_channels=16, hidden_channels=8, out_channels=1)\n",
    "model = STx_ARGVA(encoder, discriminator, l=3)\n",
    "model = model.to(device)\n",
    "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=1E-3)\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=1E-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = d[0].to(device)\n",
    "s = data.x.shape[0]\n",
    "src_mask = torch.bernoulli(torch.ones(data.x.size(0)) * 0.9).to(device)\n",
    "# x = (data.x+1).log().to(device)\n",
    "# z, _ = model.encode(None, data.x, data.edge_index,data.edge_weight, data.batch, src_mask)\n",
    "edge_index =  data.edge_index\n",
    "edge_mask = torch.bernoulli(torch.ones(edge_index.shape[1]) * 0.9)\n",
    "indices_one = torch.nonzero(edge_mask, as_tuple=True)[0]\n",
    "edge_index = edge_index[:,indices_one]\n",
    "# z, _ = model.encode(None, data.x, edge_index,None, data.batch, src_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(num_nodes, train_ratio=0.4):\n",
    "    mask = torch.rand(num_nodes) < train_ratio\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample ID: 151673\n"
     ]
    }
   ],
   "source": [
    "sample_id = [\"151673\"]\n",
    "d = SGEDataset(raw_dir='/shareN/data8/SwapTmp/fy/Spatial/ARGA-ARVGA/SGE2/raw',id=sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder = STx_encoder(in_channels=N,\n",
    "              hidden_channels=96,\n",
    "              out_channels=16,\n",
    "              m=7, l=3, K=3,\n",
    "              connect=con, pi=0.75, n_heads=8)\n",
    "discriminator = STx_discriminator(in_channels=16, hidden_channels=8, out_channels=1)\n",
    "model = STx_ARGVA(encoder, discriminator, l=3)\n",
    "model = model.to(device)\n",
    "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=1E-3)\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=1E-4)\n",
    "\n",
    "model1 = model\n",
    "model1.load_state_dict(torch.load(\"/shareN/data8/SwapTmp/fy/Spatial/ARGA-ARVGA/SGE2/result/mask/best_model_edge_mask1_73.pkl\"))\n",
    "model1.eval()\n",
    "\n",
    "model = model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (7x48 and 192x384)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m best_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2000\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     loss_reg, loss_recon, loss_clust, auc \u001b[38;5;241m=\u001b[39m test(d[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(auc \u001b[38;5;241m>\u001b[39m best_value):\n",
      "Cell \u001b[0;32mIn[22], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m     14\u001b[0m indices_one \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnonzero(edge_mask, as_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     15\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m edge_index[:,indices_one]\n\u001b[0;32m---> 16\u001b[0m z, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m w \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m__u__\n\u001b[1;32m     18\u001b[0m cl \u001b[38;5;241m=\u001b[39m w\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 159\u001b[0m, in \u001b[0;36mSTx_ARGVA.encode\u001b[0;34m(self, s, x, edge_index, edge_weight, batch, mask)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s: torch\u001b[38;5;241m.\u001b[39mTensor, \n\u001b[1;32m    154\u001b[0m                 x: torch\u001b[38;5;241m.\u001b[39mTensor, \n\u001b[1;32m    155\u001b[0m                 edge_index: torch\u001b[38;5;241m.\u001b[39mTensor, \n\u001b[1;32m    156\u001b[0m                 edge_weight: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    157\u001b[0m                 batch: torch\u001b[38;5;241m.\u001b[39mTensor, \n\u001b[1;32m    158\u001b[0m                 mask: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__u__, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__m__, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__v__, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__A__, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__e__, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__b__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__A__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__A__\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39mMIN, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mMAX)\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__logstd__ \u001b[38;5;241m=\u001b[39m  torch\u001b[38;5;241m.\u001b[39mcat([\n\u001b[1;32m    162\u001b[0m                     torch\u001b[38;5;241m.\u001b[39mmatmul(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__A__[i]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mt(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__A__[i]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mdiag()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    163\u001b[0m                         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__m__\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    164\u001b[0m                     ])\u001b[38;5;241m.\u001b[39mlog() \n",
      "File \u001b[0;32m~/.conda/envs/geometric2/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[20], line 60\u001b[0m, in \u001b[0;36mSTx_encoder.forward\u001b[0;34m(self, x, edge_index, edge_weight, batch, mask)\u001b[0m\n\u001b[1;32m     56\u001b[0m mu \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# x = self.conv2(x, _, batch)\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# y = self.conv3(x, _, batch)\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# z = x + y\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m u, mu, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x), \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, edge_index, batch\n",
      "File \u001b[0;32m~/.conda/envs/geometric2/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/geometric2/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/geometric2/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/geometric2/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (7x48 and 192x384)"
     ]
    }
   ],
   "source": [
    "f = open(r'/shareN/data8/SwapTmp/fy/Spatial/ARGA-ARVGA/SGE2/result/edge_index/train.csv', 'w')\n",
    "f1 = open(r'/shareN/data8/SwapTmp/fy/Spatial/ARGA-ARVGA/SGE2/result/edge_index/test.csv', 'w')\n",
    "f.writelines(['epoch,','loss,', 'reg loss,', 'recon_loss,', 'class loss,',  'ari,','acc,','nmi,', 'auc,','ap,','acc1,','sample\\n'])\n",
    "f1.writelines(['epoch,','loss,', 'reg loss,',  'recon_loss,', 'class loss,','ari,','acc,','nmi,', 'auc,','ap,','acc1,','sample\\n'])\n",
    "encoder = STx_encoder(in_channels=N,\n",
    "                hidden_channels=96,\n",
    "                out_channels=16,\n",
    "                m=7, l=3, K=3,\n",
    "                connect=con, pi=0.75, n_heads=8)\n",
    "discriminator = STx_discriminator(in_channels=16, hidden_channels=8, out_channels=1)\n",
    "model = STx_ARGVA(encoder, discriminator, l=3)\n",
    "model = model.to(device)\n",
    "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=1E-2)\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=1E-3)\n",
    "best_value = 0\n",
    "for epoch in range(1, 2000):\n",
    "    loss = train(d[0])\n",
    "    loss_reg, loss_recon, loss_clust, auc = test(d[1])\n",
    "    if(auc > best_value):\n",
    "        print(f\"Now best model is epoch{epoch}\")\n",
    "        best_value = auc\n",
    "        best_model = model.state_dict()\n",
    "        torch.save(best_model, os.path.join(r'/shareN/data8/SwapTmp/fy/Spatial/ARGA-ARVGA/SGE2/result/edge_index/',rf'best_model_edge.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (7x48 and 192x384)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m best_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     loss_reg, loss_recon, loss_clust, auc \u001b[38;5;241m=\u001b[39m test(d[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(auc \u001b[38;5;241m>\u001b[39m best_value):\n",
      "Cell \u001b[0;32mIn[52], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m     14\u001b[0m indices_one \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnonzero(edge_mask, as_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     15\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m edge_index[:,indices_one]\n\u001b[0;32m---> 16\u001b[0m z, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m w \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m__u__\n\u001b[1;32m     18\u001b[0m cl \u001b[38;5;241m=\u001b[39m w\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[50], line 158\u001b[0m, in \u001b[0;36mSTx_ARGVA.encode\u001b[0;34m(self, s, x, edge_index, edge_weight, batch, mask)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s: torch\u001b[38;5;241m.\u001b[39mTensor, \n\u001b[1;32m    153\u001b[0m                 x: torch\u001b[38;5;241m.\u001b[39mTensor, \n\u001b[1;32m    154\u001b[0m                 edge_index: torch\u001b[38;5;241m.\u001b[39mTensor, \n\u001b[1;32m    155\u001b[0m                 edge_weight: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    156\u001b[0m                 batch: torch\u001b[38;5;241m.\u001b[39mTensor, \n\u001b[1;32m    157\u001b[0m                 mask: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__u__, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__m__, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__v__, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__A__, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__e__, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__b__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__A__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__A__\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39mMIN, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mMAX)\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__logstd__ \u001b[38;5;241m=\u001b[39m  torch\u001b[38;5;241m.\u001b[39mcat([\n\u001b[1;32m    161\u001b[0m                     torch\u001b[38;5;241m.\u001b[39mmatmul(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__A__[i]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mt(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__A__[i]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mdiag()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    162\u001b[0m                         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__m__\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    163\u001b[0m                     ])\u001b[38;5;241m.\u001b[39mlog() \n",
      "File \u001b[0;32m~/.conda/envs/geometric2/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[50], line 60\u001b[0m, in \u001b[0;36mSTx_encoder.forward\u001b[0;34m(self, x, edge_index, edge_weight, batch, mask)\u001b[0m\n\u001b[1;32m     56\u001b[0m mu \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# x = self.conv2(x, _, batch)\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# y = self.conv3(x, _, batch)\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# z = x + y\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m u, mu, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x), \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, edge_index, batch\n",
      "File \u001b[0;32m~/.conda/envs/geometric2/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/geometric2/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/geometric2/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/geometric2/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (7x48 and 192x384)"
     ]
    }
   ],
   "source": [
    "f = open(r'/shareN/data8/SwapTmp/fy/Spatial/ARGA-ARVGA/SGE2/result/Li_0515/train_con_73.csv', 'w')\n",
    "f1 = open(r'/shareN/data8/SwapTmp/fy/Spatial/ARGA-ARVGA/SGE2/result/Li_0515/test_con_73.csv', 'w')\n",
    "f.writelines(['epoch,','loss,', 'reg loss,', 'recon_loss,', 'class loss,',  'ari,','acc,','nmi,', 'auc,','ap,','acc1,','sample\\n'])\n",
    "f1.writelines(['epoch,','loss,', 'reg loss,',  'recon_loss,', 'class loss,','ari,','acc,','nmi,', 'auc,','ap,','acc1,','sample\\n'])\n",
    "encoder = STx_encoder(in_channels=N,\n",
    "              hidden_channels=96,\n",
    "              out_channels=16,\n",
    "              m=7, l=3, K=8,\n",
    "              connect=con, pi=0.75, n_heads=8)\n",
    "discriminator = STx_discriminator(in_channels=16, hidden_channels=8, out_channels=1)\n",
    "model = STx_ARGVA(encoder, discriminator, l=3)\n",
    "model = model.to(device)\n",
    "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=1E-3)\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=1E-4)\n",
    "best_value = 0\n",
    "for epoch in range(1, 1000):\n",
    "    loss = train(d[0])\n",
    "    loss_reg, loss_recon, loss_clust, auc = test(d[1])\n",
    "    if(auc > best_value):\n",
    "        print(f\"Now best model is epoch{epoch}\")\n",
    "        best_value = auc\n",
    "        best_model = model.state_dict()\n",
    "        torch.save(best_model, os.path.join(r'/shareN/data8/SwapTmp/fy/Spatial/ARGA-ARVGA/SGE2/result/Li_0515/',rf'best_model_edge_con_73.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = STx_encoder(in_channels=N, \n",
    "             hidden_channels=96, \n",
    "             out_channels=32, \n",
    "             m=7, l=2, K=8,\n",
    "             connect=con, pi=0.75, n_heads=8)\n",
    "discriminator = STx_discriminator(in_channels=32, hidden_channels=8, out_channels=1)\n",
    "model = STx_ARGVA(encoder, discriminator, l=2)\n",
    "model = model.to(device)\n",
    "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=1E-4)\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=1E-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:1 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#f = open(r'argva0516.csv', 'a')\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m501\u001b[39m):\n\u001b[0;32m----> 6\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     loss_reg, loss_recon, loss_clust \u001b[38;5;241m=\u001b[39m test(d[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      8\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite( \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mtensor([loss, loss_reg, loss_recon, loss_clust])\u001b[38;5;241m.\u001b[39mnumpy())))\n",
      "Cell \u001b[0;32mIn[19], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m     11\u001b[0m src_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbernoulli(torch\u001b[38;5;241m.\u001b[39mones(data\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.8\u001b[39m)\n\u001b[1;32m     12\u001b[0m src_mask \u001b[38;5;241m=\u001b[39m src_mask\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 13\u001b[0m z, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m     15\u001b[0m     discriminator\u001b[38;5;241m.\u001b[39mtrain()\n",
      "Cell \u001b[0;32mIn[10], line 173\u001b[0m, in \u001b[0;36mSTx_ARGVA.encode\u001b[0;34m(self, s, x, edge_index, batch, mask)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s: torch\u001b[38;5;241m.\u001b[39mTensor, \n\u001b[1;32m    169\u001b[0m                 x: torch\u001b[38;5;241m.\u001b[39mTensor, \n\u001b[1;32m    170\u001b[0m                 edge_index: torch\u001b[38;5;241m.\u001b[39mTensor, \n\u001b[1;32m    171\u001b[0m                 batch: torch\u001b[38;5;241m.\u001b[39mTensor, \n\u001b[1;32m    172\u001b[0m                 mask: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__u__, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__m__, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__v__, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__A__, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__e__, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__b__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__A__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__A__\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39mMIN, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mMAX)\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__logstd__ \u001b[38;5;241m=\u001b[39m  torch\u001b[38;5;241m.\u001b[39mcat([\n\u001b[1;32m    176\u001b[0m                     torch\u001b[38;5;241m.\u001b[39mmatmul(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__A__[i]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mt(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__A__[i]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mdiag()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    177\u001b[0m                         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__m__\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    178\u001b[0m                     ])\u001b[38;5;241m.\u001b[39mlog() \n",
      "File \u001b[0;32m~/.conda/envs/geometric2/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[10], line 66\u001b[0m, in \u001b[0;36mSTx_encoder.forward\u001b[0;34m(self, x, edge_weight, batch, mask)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_weight, batch, mask: Optional[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):   \n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m#u = self.norm0(x, batch) \u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcdist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     edge_index \u001b[38;5;241m=\u001b[39m radius_graph(x, r, batch, max_num_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)    \n\u001b[1;32m     68\u001b[0m     u \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv0(x, edge_index, edge_weight, batch)     \n",
      "File \u001b[0;32m~/.conda/envs/geometric2/lib/python3.11/site-packages/numpy/lib/function_base.py:4536\u001b[0m, in \u001b[0;36mquantile\u001b[0;34m(a, q, axis, out, overwrite_input, method, keepdims, interpolation)\u001b[0m\n\u001b[1;32m   4532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpolation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4533\u001b[0m     method \u001b[38;5;241m=\u001b[39m _check_interpolation_as_method(\n\u001b[1;32m   4534\u001b[0m         method, interpolation, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantile\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 4536\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   4538\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma must be an array of real numbers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/geometric2/lib/python3.11/site-packages/torch/_tensor.py:970\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 970\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    972\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:1 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "f = open(r'argva0516.csv', 'w')\n",
    "f.writelines(['train loss,', 'test reg loss,', 'test recon loss,', 'test clust-loss\\n'])\n",
    "f.close()\n",
    "#f = open(r'argva0516.csv', 'a')\n",
    "for epoch in range(1, 501):\n",
    "    loss = train(d[0])\n",
    "    loss_reg, loss_recon, loss_clust = test(d[1])\n",
    "    f.write( ','.join(map(str, torch.tensor([loss, loss_reg, loss_recon, loss_clust]).numpy())))\n",
    "    f.write('\\n')\n",
    "    print((f'Epoch: {epoch:03d}, Loss: {loss:.3f}, Test loss reg: {loss_reg:.3f}, '\n",
    "           f'Test loss recon: {loss_recon:.3f}, Test clust-loss: {loss_clust:.3f}')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ari: 0.6696482423793315\n",
      "acc: 0.8274946921443737\n",
      "nmi: 0.7148373106616541\n",
      "auc: 0.8846254823364205\n",
      "ap: 0.8491499006955852\n",
      "acc1: 0.7717816500711238\n",
      "ari: 0.6486621723492817\n",
      "acc: 0.8199189345686161\n",
      "nmi: 0.7076036215198002\n",
      "auc: 0.8984042839701235\n",
      "ap: 0.8635687305466829\n",
      "acc1: 0.8167372881355932\n"
     ]
    }
   ],
   "source": [
    "for data in d:\n",
    "    data = data.to(device)\n",
    "    z, _ = model.encode(None, data.x, data.edge_index,None, None, None)\n",
    "    w = model.__u__\n",
    "    cl = w.cpu().softmax(dim=-1)\n",
    "    s = data.x.shape[0]\n",
    "    ari = adjusted_rand_score(onehot_to_label(cl.t()).values.reshape(-1), data.y.cpu())\n",
    "    acc = accuracy_score(data.y.cpu(), onehot_to_label(cl.t()).values.reshape(-1))\n",
    "    nmi =  normalized_mutual_info_score(data.y.cpu(), onehot_to_label(cl.t()).values.reshape(-1))\n",
    "    # ami = adjusted_mutual_info_score(data.y.cpu(), onehot_to_label(cl.t()).values.reshape(-1))\n",
    "    # print(ari)\n",
    "    # loss = 0\n",
    "    adj = model.decoder.forward_all(z)\n",
    "    auroc,ap_score,acc_score = cal_auc_ap_acc(1,data.edge_index,z,adj)\n",
    "    auc = np.mean(auroc)\n",
    "    ap = np.mean(ap_score)\n",
    "    acc1 = np.mean(acc_score)\n",
    "    print(\"ari:\",ari)\n",
    "    print(\"acc:\",acc)\n",
    "    print(\"nmi:\",nmi)\n",
    "    print(\"auc:\",auc)\n",
    "    print(\"ap:\",ap)\n",
    "    print(\"acc1:\",acc1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "indices_k = model.encoder.conv2.knet.state_dict()['0.indices']\n",
    "indices_q = model.encoder.conv2.qnet.state_dict()['0.indices']\n",
    "weight_k = model.encoder.conv2.knet.state_dict()['0.weights']\n",
    "weight_q = model.encoder.conv2.qnet.state_dict()['0.weights']\n",
    "\n",
    "\n",
    "\n",
    "# 初始化 n x 2n 矩阵\n",
    "n = con[0].max()+ 1  # 基于 con 中的最大索引计算 n\n",
    "matrix_q = torch.zeros((n, 2*n))\n",
    "\n",
    "# 填充权重\n",
    "for i in range(indices_q.shape[1]):\n",
    "    start, end = indices_q[:, i]\n",
    "    matrix_q[start, end] = weight_q[i]\n",
    "# 填充权重值\n",
    "matrix_k = torch.zeros((n, 2*n))\n",
    "for i in range(indices_k.shape[1]):\n",
    "    start, end = indices_k[:, i]\n",
    "    matrix_k[start, end] = weight_k[i]\n",
    "# 此时 matrix 为根据连接和权重构建的 n x 2n 矩阵\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.matmul(matrix_k.T,matrix_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 300\n",
    "values, flat_indices = w.view(-1).topk(k)\n",
    "indices_2d = torch.stack((flat_indices // w.size(1), flat_indices % w.size(1)))\n",
    "indices_2d\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "indices = pd.DataFrame(indices_2d.detach().cpu().T)\n",
    "indices['values'] = values.detach().cpu()\n",
    "indices.columns = [\"row1\",\"row2\",\"values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi.columns = [\"0\",\"row1\",\"row2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_df = pd.DataFrame(con.detach().cpu().T)\n",
    "con_df.columns = [\"row1\",\"row2\"]\n",
    "\n",
    "result = pd.merge(indices,con_df, on=['row1', 'row2'],how = \"left\")\n",
    "indices.columns = [\"row1\",\"row2\",\"values\"]\n",
    "\n",
    "ppi1 = ppi\n",
    "ppi1[['Protein1', 'Protein2']] = ppi1.iloc[:, 0].str.split('-', expand=True,n=1)\n",
    "\n",
    "df_row1_protein1 = ppi1[['row1', 'Protein1']].rename(columns={'row1': 'row', 'Protein1': 'Protein'})\n",
    "df_row2_protein2 = ppi1[['row2', 'Protein2']].rename(columns={'row2': 'row', 'Protein2': 'Protein'})\n",
    "\n",
    "new_df = pd.concat([df_row1_protein1, df_row2_protein2], ignore_index=True)\n",
    "new_df.drop_duplicates()\n",
    "\n",
    "row_to_protein = pd.Series(new_df.Protein.values,index=new_df.row).to_dict()\n",
    "result['Protein1'] = result['row1'].map(row_to_protein)\n",
    "result['Protein2'] = result['row2'].map(row_to_protein)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"/shareN/data8/SwapTmp/fy/Spatial/ARGA-ARVGA/SGE2/result/mask/result_73.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geometric2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
